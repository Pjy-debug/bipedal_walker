nohup: 忽略输入
Namespace(batch_size=64, output_model_prefix='mlp', start_epoch=801, epochs=900, lr=0.0001, no_cuda=False, final_ratio=0, start_ratio=0, warm_up_epochs=20, threshold=0.5, input_dim=107, embed_dim=256, embed_dim_1=256, embed_dim_2=1024, n_layers=6, n_heads=8, dropout=0.1, ffn_dim=1024, num_classes=2, max_seq_len=11, dataset_dir='/mnt1/hyj/Acc_Test/tta_new/data/test_2025-6-8/processed_data/', log_dir='../new_log/log', is_resume=0, is_chuan=0, model_path='storage/mlp.ep546', best_model_path='storage/mlp.ep680', first_model_path='storage/mlp.ep546', two_model=1)
ratio is 0,loading data...
pos data is being loaded...
neg data is being loaded...
len of data pos is 780, len of data neg is 321336
train_pos_size is 546, val_pos_size is 78, test_pos_size is 156
train_neg_size is 224935, val_neg_size is 32134, test_neg_size is 64267
num of pos is 546
num of neg is 224935
224935 546
num of pos is 546,num of neg is 224935,ratio is 411.96886446886447
num of pos is {}, num of neg is {} 546 224935
  0%|          | 0/225481 [00:00<?, ?it/s]  3%|▎         | 6252/225481 [00:00<00:03, 62507.69it/s]  7%|▋         | 14950/225481 [00:00<00:02, 76897.84it/s] 10%|█         | 23475/225481 [00:00<00:02, 80708.55it/s] 14%|█▍        | 32184/225481 [00:00<00:02, 83180.14it/s] 18%|█▊        | 40533/225481 [00:00<00:02, 83287.43it/s] 22%|██▏       | 48935/225481 [00:00<00:02, 83531.92it/s] 25%|██▌       | 57289/225481 [00:00<00:02, 83091.12it/s] 29%|██▉       | 66038/225481 [00:00<00:01, 83828.41it/s] 33%|███▎      | 74421/225481 [00:00<00:01, 83725.05it/s] 37%|███▋      | 82794/225481 [00:01<00:01, 82569.21it/s] 40%|████      | 91054/225481 [00:01<00:01, 80909.03it/s] 44%|████▍     | 99331/225481 [00:01<00:01, 81458.25it/s] 48%|████▊     | 107483/225481 [00:01<00:01, 79168.75it/s] 52%|█████▏    | 116294/225481 [00:01<00:01, 81193.51it/s] 55%|█████▌    | 124670/225481 [00:01<00:01, 81236.41it/s] 59%|█████▉    | 133115/225481 [00:01<00:01, 82177.89it/s] 63%|██████▎   | 141842/225481 [00:01<00:00, 83679.82it/s] 67%|██████▋   | 150496/225481 [00:01<00:00, 84497.27it/s] 71%|███████   | 159370/225481 [00:01<00:00, 85757.96it/s] 75%|███████▍  | 168083/225481 [00:02<00:00, 86164.12it/s] 79%|███████▊  | 177176/225481 [00:02<00:00, 87585.78it/s] 83%|████████▎ | 186050/225481 [00:02<00:00, 87928.29it/s] 86%|████████▋ | 194988/225481 [00:02<00:00, 88356.22it/s] 90%|█████████ | 203826/225481 [00:02<00:00, 87525.32it/s] 94%|█████████▍| 212618/225481 [00:02<00:00, 87139.20it/s] 98%|█████████▊| 221335/225481 [00:02<00:00, 86934.82it/s]100%|██████████| 225481/225481 [00:02<00:00, 83957.14it/s]
32134 78
sampling...
num of pos is 78,num of neg is 500,ratio is 6.410256410256411
num of pos is {}, num of neg is {} 78 500
  0%|          | 0/578 [00:00<?, ?it/s]100%|██████████| 578/578 [00:00<00:00, 74115.19it/s]
64267 156
num of pos is 156,num of neg is 64267,ratio is 411.96794871794873
num of pos is {}, num of neg is {} 156 64267
  0%|          | 0/64423 [00:00<?, ?it/s] 12%|█▏        | 7866/64423 [00:00<00:00, 78649.01it/s] 26%|██▌       | 16643/64423 [00:00<00:00, 84010.74it/s] 39%|███▉      | 25390/64423 [00:00<00:00, 85586.63it/s] 53%|█████▎    | 34209/64423 [00:00<00:00, 86610.39it/s] 67%|██████▋   | 42871/64423 [00:00<00:00, 84078.94it/s] 80%|████████  | 51559/64423 [00:00<00:00, 85009.40it/s] 94%|█████████▎| 60378/64423 [00:00<00:00, 86031.53it/s]100%|██████████| 64423/64423 [00:00<00:00, 85472.62it/s]
Successfully build train datasets!
Successfully build val datasets!
Successfully build test datasets!
Train & Validate
  0%|          | 0/99 [00:00<?, ?it/s]/home/teamcommon/pjy/Bipedal_walker/criticality/stage2/trainer_bing.py:179: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels_cls1 = torch.tensor(labels1[:,0],dtype=torch.int64)
/home/teamcommon/pjy/Bipedal_walker/criticality/stage2/trainer_bing.py:187: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels_cls2 = torch.tensor(labels2[:,0],dtype=torch.int64)
/home/teamcommon/pjy/Bipedal_walker/criticality/stage2/trainer_bing.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels_cls = torch.tensor(labels[:, 0],dtype=torch.int64)
  1%|          | 1/99 [00:00<01:25,  1.15it/s]  2%|▏         | 2/99 [00:01<00:55,  1.76it/s]  3%|▎         | 3/99 [00:01<00:45,  2.10it/s]  4%|▍         | 4/99 [00:01<00:40,  2.32it/s]  5%|▌         | 5/99 [00:02<00:37,  2.49it/s]  6%|▌         | 6/99 [00:02<00:36,  2.56it/s]  7%|▋         | 7/99 [00:03<00:35,  2.63it/s]  8%|▊         | 8/99 [00:03<00:33,  2.68it/s]  9%|▉         | 9/99 [00:03<00:33,  2.73it/s] 10%|█         | 10/99 [00:04<00:32,  2.73it/s] 11%|█         | 11/99 [00:04<00:31,  2.76it/s] 12%|█▏        | 12/99 [00:04<00:31,  2.76it/s] 13%|█▎        | 13/99 [00:05<00:31,  2.76it/s] 14%|█▍        | 14/99 [00:05<00:30,  2.78it/s] 15%|█▌        | 15/99 [00:05<00:29,  2.81it/s] 16%|█▌        | 16/99 [00:06<00:29,  2.78it/s] 17%|█▋        | 17/99 [00:06<00:29,  2.78it/s] 18%|█▊        | 18/99 [00:06<00:29,  2.78it/s] 19%|█▉        | 19/99 [00:07<00:28,  2.76it/s] 20%|██        | 20/99 [00:07<00:28,  2.77it/s] 21%|██        | 21/99 [00:08<00:28,  2.76it/s] 22%|██▏       | 22/99 [00:08<00:28,  2.72it/s] 23%|██▎       | 23/99 [00:08<00:27,  2.74it/s] 24%|██▍       | 24/99 [00:09<00:27,  2.77it/s] 25%|██▌       | 25/99 [00:09<00:26,  2.76it/s] 26%|██▋       | 26/99 [00:09<00:26,  2.76it/s] 27%|██▋       | 27/99 [00:10<00:25,  2.77it/s] 28%|██▊       | 28/99 [00:10<00:25,  2.76it/s] 29%|██▉       | 29/99 [00:10<00:25,  2.76it/s] 30%|███       | 30/99 [00:11<00:25,  2.73it/s] 31%|███▏      | 31/99 [00:11<00:25,  2.72it/s]
epoch: 801, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.011744259856641293
weight = 0.0
loss_1 = 0.6931474804878235, loss_2 = 0.011744259856641293

epoch: 802, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.010916410324474176
weight = 0.0001020304050607081
loss_1 = 0.5446271896362305, loss_2 = 0.010861950305600962

epoch: 803, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.0109159459049503
weight = 0.0004081216202428324
loss_1 = 0.5331935087839762, loss_2 = 0.010702705942094326

epoch: 804, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.010632241144776344
weight = 0.0009182736455463729
loss_1 = 0.5181525349617004, loss_2 = 0.010165770538151264

epoch: 805, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.011770392147203287
weight = 0.0016324864809713297
loss_1 = 0.5277948975563049, loss_2 = 0.010926612031956514

epoch: 806, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.011374379508197308
weight = 0.002550760126517702
loss_1 = 0.5134608149528503, loss_2 = 0.01009040263791879

epoch: 807, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.012657561339437962
weight = 0.0036730945821854917
loss_1 = 0.5239590803782145, loss_2 = 0.010772578418254852

epoch: 808, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.013025601394474506
weight = 0.004999489847974696
loss_1 = 0.5186187823613485, loss_2 = 0.010485192760825157

epoch: 809, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.013477825870116552
weight = 0.006529945923885319
loss_1 = 0.5131832857926687, loss_2 = 0.010193328373134136

epoch: 810, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.015130531042814255
weight = 0.008264462809917356
loss_1 = 0.5239212910334269, loss_2 = 0.010890608342985312

epoch: 811, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.015148110687732697
weight = 0.010203040506070809
loss_1 = 0.5102942089239756, loss_2 = 0.01004403829574585

epoch: 812, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.017218435183167458
weight = 0.012345679012345678
loss_1 = 0.5236284136772156, loss_2 = 0.01088831014931202

epoch: 813, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.01842009462416172
weight = 0.014692378328741967
loss_1 = 0.5235580603281657, loss_2 = 0.010887748251358667

epoch: 814, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.019726600497961044
weight = 0.017243138455259672
loss_1 = 0.5235108931859335, loss_2 = 0.01088736237337192

epoch: 815, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.0207715705037117
weight = 0.019997959391898783
loss_1 = 0.5189940532048544, loss_2 = 0.010604822697738806

epoch: 816, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.022843549648920696
weight = 0.022956841138659322
loss_1 = 0.5257082978884379, loss_2 = 0.011028119052449862

epoch: 817, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.02329447182516257
weight = 0.026119783695541274
loss_1 = 0.5122336049874624, loss_2 = 0.010180965686837832

epoch: 818, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.025592712685465813
weight = 0.029486787062544637
loss_1 = 0.5189225474993387, loss_2 = 0.010604032936195532

epoch: 819, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.028037441273530323
weight = 0.03305785123966942
loss_1 = 0.5255869626998901, loss_2 = 0.011027202320595583

epoch: 820, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.029976985106865566
weight = 0.036832976226915615
loss_1 = 0.5255192915598551, loss_2 = 0.011026691334942976

epoch: 821, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.03133914309243361
weight = 0.040812162024283234
loss_1 = 0.5187166531880697, loss_2 = 0.010601880960166454

epoch: 822, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.03346194326877594
weight = 0.044995408631772274
loss_1 = 0.5186663667360941, loss_2 = 0.010601351658503214

epoch: 823, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.03667105113466581
weight = 0.04938271604938271
loss_1 = 0.5276230971018473, loss_2 = 0.01116704847663641

epoch: 824, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.03878547872106234
weight = 0.05397408427711458
loss_1 = 0.5253493587176005, loss_2 = 0.011025308320919672

epoch: 825, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.04018950338164965
weight = 0.05876951331496787
loss_1 = 0.5163456002871195, loss_2 = 0.010458781073490778

epoch: 826, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.04354700818657875
weight = 0.06376900316294257
loss_1 = 0.5231019457181295, loss_2 = 0.010883338438967863

epoch: 827, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.04535567263762156
weight = 0.06897255382103869
loss_1 = 0.5164122978846232, loss_2 = 0.010458767103652159

epoch: 828, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.047806307673454285
weight = 0.07438016528925619
loss_1 = 0.5143232345581055, loss_2 = 0.010318338560561338

epoch: 829, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.05158948401610056
weight = 0.07999183756759513
loss_1 = 0.5213735898335775, loss_2 = 0.010743219094971815

epoch: 830, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.053359837581714
weight = 0.0858075706560555
loss_1 = 0.513308048248291, loss_2 = 0.010188360077639421

epoch: 831, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.05789270500342051
weight = 0.09182736455463729
loss_1 = 0.5240529378255209, loss_2 = 0.010758205937842527

epoch: 832, start epoch: 801, L: 99
 32%|███▏      | 32/99 [00:12<00:24,  2.74it/s] 33%|███▎      | 33/99 [00:12<00:24,  2.71it/s] 34%|███▍      | 34/99 [00:12<00:23,  2.71it/s] 35%|███▌      | 35/99 [00:13<00:23,  2.68it/s] 36%|███▋      | 36/99 [00:13<00:23,  2.70it/s] 37%|███▋      | 37/99 [00:13<00:23,  2.70it/s] 38%|███▊      | 38/99 [00:14<00:22,  2.72it/s] 39%|███▉      | 39/99 [00:14<00:21,  2.73it/s] 40%|████      | 40/99 [00:15<00:21,  2.74it/s] 41%|████▏     | 41/99 [00:15<00:21,  2.74it/s] 42%|████▏     | 42/99 [00:15<00:20,  2.77it/s] 43%|████▎     | 43/99 [00:16<00:20,  2.74it/s] 44%|████▍     | 44/99 [00:16<00:20,  2.75it/s] 45%|████▌     | 45/99 [00:16<00:19,  2.76it/s] 46%|████▋     | 46/99 [00:17<00:19,  2.74it/s] 47%|████▋     | 47/99 [00:17<00:19,  2.73it/s] 48%|████▊     | 48/99 [00:17<00:18,  2.73it/s] 49%|████▉     | 49/99 [00:18<00:18,  2.74it/s] 51%|█████     | 50/99 [00:18<00:17,  2.75it/s] 52%|█████▏    | 51/99 [00:19<00:17,  2.76it/s] 53%|█████▎    | 52/99 [00:19<00:17,  2.76it/s] 54%|█████▎    | 53/99 [00:19<00:16,  2.78it/s] 55%|█████▍    | 54/99 [00:20<00:16,  2.77it/s] 56%|█████▌    | 55/99 [00:20<00:16,  2.74it/s] 57%|█████▋    | 56/99 [00:20<00:15,  2.76it/s] 58%|█████▊    | 57/99 [00:21<00:15,  2.76it/s] 59%|█████▊    | 58/99 [00:21<00:14,  2.76it/s] 60%|█████▉    | 59/99 [00:21<00:14,  2.77it/s] 61%|██████    | 60/99 [00:22<00:14,  2.77it/s] 62%|██████▏   | 61/99 [00:22<00:14,  2.71it/s] 63%|██████▎   | 62/99 [00:23<00:13,  2.71it/s]length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.05954137692848841
weight = 0.09805121926334048
loss_1 = 0.5153283874193827, loss_2 = 0.009992585517466068

epoch: 833, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.06476437548796336
weight = 0.1044791347821651
loss_1 = 0.5293986598650614, loss_2 = 0.010556157988806566

epoch: 834, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.0675144890944163
weight = 0.1111111111111111
loss_1 = 0.5255963802337646, loss_2 = 0.010254253633320332

epoch: 835, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.06863319377104442
weight = 0.11794714825017855
loss_1 = 0.5119524498780569, loss_2 = 0.009353027989466986

epoch: 836, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.07318517565727234
weight = 0.12498724619936741
loss_1 = 0.5191502173741659, loss_2 = 0.009483311014870802

epoch: 837, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.0735003153483073
weight = 0.1322314049586777
loss_1 = 0.5003428558508555, loss_2 = 0.008457644221683344

epoch: 838, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.07602794965108235
weight = 0.1396796245281094
loss_1 = 0.49132070938746136, loss_2 = 0.008601976713786522

epoch: 839, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.07757585992415746
weight = 0.14733190490766246
loss_1 = 0.48145171999931335, loss_2 = 0.0077904413143793745

epoch: 840, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.08224237461884816
weight = 0.155188246097337
loss_1 = 0.4851478735605876, loss_2 = 0.008230382887025675

epoch: 841, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.08683486531178157
weight = 0.16324864809713294
loss_1 = 0.48828856150309247, loss_2 = 0.008511989377439022

epoch: 842, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.08903479079405467
weight = 0.1715131109070503
loss_1 = 0.47993165254592896, loss_2 = 0.008111441197494665

epoch: 843, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.09215221305688222
weight = 0.1799816345270891
loss_1 = 0.47601477305094403, loss_2 = 0.007900187435249487

epoch: 844, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.09707465767860413
weight = 0.1886542189572493
loss_1 = 0.4794987738132477, loss_2 = 0.008153356611728668

epoch: 845, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.10460849106311798
weight = 0.19753086419753085
loss_1 = 0.49310067296028137, loss_2 = 0.008979649282991886

epoch: 846, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.10424325615167618
weight = 0.20661157024793386
loss_1 = 0.47461241483688354, loss_2 = 0.007792951383938392

epoch: 847, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.12386639416217804
weight = 0.21589633710845832
loss_1 = 0.5322409470876058, loss_2 = 0.011423899171253046

epoch: 848, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.11826375126838684
weight = 0.22538516477910417
loss_1 = 0.4935264786084493, loss_2 = 0.009075742214918137

epoch: 849, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.11759635806083679
weight = 0.23507805325987147
loss_1 = 0.47453763087590534, loss_2 = 0.00790012115612626

epoch: 850, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.12337744484345119
weight = 0.24497500255076016
loss_1 = 0.4786097009976705, loss_2 = 0.008118984444687763

epoch: 851, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.14030898114045462
weight = 0.25507601265177027
loss_1 = 0.5190738836924235, loss_2 = 0.010612729315956434

epoch: 852, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.13299908737341562
weight = 0.26538108356290174
loss_1 = 0.4786207675933838, loss_2 = 0.008143246794740358

epoch: 853, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.13736856480439505
weight = 0.27589021528415475
loss_1 = 0.47690510749816895, loss_2 = 0.008003092215706905

epoch: 854, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.14227711657683054
weight = 0.286603407815529
loss_1 = 0.4764116704463959, loss_2 = 0.008040267663697401

epoch: 855, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.15087675551573435
weight = 0.29752066115702475
loss_1 = 0.486706684033076, loss_2 = 0.008642890180150667

epoch: 856, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.15070168177286783
weight = 0.308641975308642
loss_1 = 0.4711098372936249, loss_2 = 0.00766233882556359

epoch: 857, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.16109625001748404
weight = 0.31996735027038054
loss_1 = 0.4851621190706889, loss_2 = 0.00861753678570191

epoch: 858, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.16625415285428366
weight = 0.33149678604224064
loss_1 = 0.4842921396096547, loss_2 = 0.008545765032370886

epoch: 859, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.16379048923651376
weight = 0.343230282624222
loss_1 = 0.46347038944562274, loss_2 = 0.007176661863923073

epoch: 860, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.17307602862517038
weight = 0.3551678400163248
loss_1 = 0.47302666306495667, loss_2 = 0.0078658830995361

epoch: 861, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.17556227246920267
weight = 0.36730945821854916
loss_1 = 0.46528170506159466, loss_2 = 0.007365216501057148

epoch: 862, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.18586362401644388
weight = 0.3796551372308948
loss_1 = 0.47641350825627643, loss_2 = 0.008045193428794542

epoch: 863, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.18662029504776
 64%|██████▎   | 63/99 [00:23<00:13,  2.70it/s] 65%|██████▍   | 64/99 [00:23<00:12,  2.70it/s] 66%|██████▌   | 65/99 [00:24<00:12,  2.71it/s] 67%|██████▋   | 66/99 [00:24<00:12,  2.73it/s] 68%|██████▊   | 67/99 [00:24<00:11,  2.72it/s] 69%|██████▊   | 68/99 [00:25<00:11,  2.73it/s] 70%|██████▉   | 69/99 [00:25<00:10,  2.77it/s] 71%|███████   | 70/99 [00:25<00:10,  2.76it/s] 72%|███████▏  | 71/99 [00:26<00:10,  2.76it/s] 73%|███████▎  | 72/99 [00:26<00:09,  2.75it/s] 74%|███████▎  | 73/99 [00:27<00:09,  2.75it/s] 75%|███████▍  | 74/99 [00:27<00:09,  2.71it/s] 76%|███████▌  | 75/99 [00:27<00:08,  2.70it/s] 77%|███████▋  | 76/99 [00:28<00:08,  2.71it/s] 78%|███████▊  | 77/99 [00:28<00:08,  2.71it/s] 79%|███████▉  | 78/99 [00:28<00:07,  2.74it/s] 80%|███████▉  | 79/99 [00:29<00:07,  2.76it/s] 81%|████████  | 80/99 [00:29<00:06,  2.77it/s] 82%|████████▏ | 81/99 [00:29<00:06,  2.73it/s] 83%|████████▎ | 82/99 [00:30<00:06,  2.73it/s] 84%|████████▍ | 83/99 [00:30<00:05,  2.69it/s] 85%|████████▍ | 84/99 [00:31<00:05,  2.70it/s] 86%|████████▌ | 85/99 [00:31<00:05,  2.72it/s] 87%|████████▋ | 86/99 [00:31<00:04,  2.71it/s] 88%|████████▊ | 87/99 [00:32<00:04,  2.73it/s] 89%|████████▉ | 88/99 [00:32<00:04,  2.75it/s] 90%|████████▉ | 89/99 [00:32<00:03,  2.74it/s] 91%|█████████ | 90/99 [00:33<00:03,  2.75it/s] 92%|█████████▏| 91/99 [00:33<00:02,  2.76it/s] 93%|█████████▎| 92/99 [00:33<00:02,  2.78it/s] 94%|█████████▍| 93/99 [00:34<00:02,  2.76it/s] 95%|█████████▍| 94/99 [00:34<00:01,  2.75it/s]weight = 0.39220487705336193
loss_1 = 0.46452651421229046, loss_2 = 0.007289836959292491

epoch: 864, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.19477449854214987
weight = 0.4049586776859504
loss_1 = 0.4697359601656596, loss_2 = 0.007647958428909381

epoch: 865, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.20097277561823526
weight = 0.4179165391286604
loss_1 = 0.47018106778462726, loss_2 = 0.007690191424141328

epoch: 866, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.2095552682876587
weight = 0.4310784613814917
loss_1 = 0.47551266352335614, loss_2 = 0.008036251179873943

epoch: 867, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.20874479909737906
weight = 0.4444444444444444
loss_1 = 0.4607899884382884, loss_2 = 0.007108650791148345

epoch: 868, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.2206359306971232
weight = 0.4580144883175187
loss_1 = 0.47243016958236694, loss_2 = 0.007852730496476093

epoch: 869, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.2254451165596644
weight = 0.4717885930007142
loss_1 = 0.46927712361017865, loss_2 = 0.007658911558489005

epoch: 870, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.23360797762870789
weight = 0.4857667584940313
loss_1 = 0.4725830852985382, loss_2 = 0.007861838520814976

epoch: 871, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.23987987637519836
weight = 0.49994898479746963
loss_1 = 0.4719947079817454, loss_2 = 0.00781240841994683

epoch: 872, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.24476363261540732
weight = 0.5143352719110295
loss_1 = 0.4687161445617676, loss_2 = 0.007590400365491708

epoch: 873, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.2458098183075587
weight = 0.5289256198347108
loss_1 = 0.45850521326065063, loss_2 = 0.006993954535573721

epoch: 874, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.25296901166439056
weight = 0.5437200285685134
loss_1 = 0.45934905608495075, loss_2 = 0.007038947660475969

epoch: 875, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.26396342118581134
weight = 0.5587184981124376
loss_1 = 0.46654194593429565, loss_2 = 0.007473262337346871

epoch: 876, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.275317261616389
weight = 0.573921028466483
loss_1 = 0.47381136814753216, loss_2 = 0.007949138836314281

epoch: 877, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.2790987491607666
weight = 0.5893276196306498
loss_1 = 0.46828846136728924, loss_2 = 0.007605607000490029

epoch: 878, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.28892351190249127
weight = 0.6049382716049383
loss_1 = 0.4724523325761159, loss_2 = 0.007894999502847591

epoch: 879, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.32169901331265766
weight = 0.620752984389348
loss_1 = 0.5119011203447977, loss_2 = 0.010375439810256163

epoch: 880, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.3057444393634796
weight = 0.6367717579838792
loss_1 = 0.475554754336675, loss_2 = 0.00805172851930062

epoch: 881, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.3076893190542857
weight = 0.6529945923885317
loss_1 = 0.4671955406665802, loss_2 = 0.007530659902840853

epoch: 882, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.3221030632654826
weight = 0.6694214876033059
loss_1 = 0.47711731990178424, loss_2 = 0.008199201431125402

epoch: 883, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.32498647769292194
weight = 0.6860524436282012
loss_1 = 0.4701856275399526, loss_2 = 0.007690731901675463

epoch: 884, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.3344180981318156
weight = 0.7028874604632179
loss_1 = 0.47245510419209796, loss_2 = 0.007860061091681322

epoch: 885, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.334782342116038
weight = 0.7199265381083564
loss_1 = 0.4622102677822113, loss_2 = 0.007229883534212907

epoch: 886, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.3647800385951996
weight = 0.7371696765636159
loss_1 = 0.4915949006875356, loss_2 = 0.009097816422581673

epoch: 887, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.3661533792813619
weight = 0.7546168758289972
loss_1 = 0.48244701822598773, loss_2 = 0.00852027970055739

epoch: 888, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.36108605066935223
weight = 0.7722681359044995
loss_1 = 0.4653558333714803, loss_2 = 0.007493781701972087

epoch: 889, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.37033472458521527
weight = 0.7901234567901234
loss_1 = 0.46669431527455646, loss_2 = 0.007569181888053815

epoch: 890, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.3771851559480031
weight = 0.8081828384858688
loss_1 = 0.46493255098660785, loss_2 = 0.0074792470162113505

epoch: 891, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.396592378616333
weight = 0.8264462809917354
loss_1 = 0.47813600301742554, loss_2 = 0.00828938124080499

epoch: 892, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.40354398886362713
weight = 0.8449137843077238
loss_1 = 0.47611089547475177, loss_2 = 0.008197575807571411

epoch: 893, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.4096365173657735
weight = 0.8635853484338333
loss_1 = 0.47306928038597107, loss_2 = 0.008069701182345549

epoch: 894, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.41257039705912274
weight = 0.8824609733700643
loss_1 = 0.46650245785713196, loss_2 = 0.00765872389699022

epoch: 895, start epoch: 801, L: 99
 96%|█████████▌| 95/99 [00:35<00:01,  2.77it/s] 97%|█████████▋| 96/99 [00:35<00:01,  2.73it/s] 98%|█████████▊| 97/99 [00:35<00:00,  2.74it/s] 99%|█████████▉| 98/99 [00:36<00:00,  2.76it/s]100%|██████████| 99/99 [00:36<00:00,  2.72it/s]100%|██████████| 99/99 [00:36<00:00,  2.71it/s]
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.45246734221776325
weight = 0.9015406591164167
loss_1 = 0.5008097986380259, loss_2 = 0.009820892785986265

epoch: 896, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.4215148389339447
weight = 0.9208244056728905
loss_1 = 0.4571490486462911, loss_2 = 0.00708353395263354

epoch: 897, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.44237325588862103
weight = 0.9403122130394859
loss_1 = 0.4699517786502838, loss_2 = 0.007905536486456791

epoch: 898, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.45414677262306213
weight = 0.9600040812162024
loss_1 = 0.47273000081380206, loss_2 = 0.008101506624370813

epoch: 899, start epoch: 801, L: 99
length of train_pos_loader: 8, length of train_neg_loader1: 3514, length of train_neg_loader2: 1761
average loss = 0.4855530460675557
weight = 0.9799000102030406
loss_1 = 0.4953176975250244, loss_2 = 0.00951405211041371
epoch_list: [801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899], loss_list: [0.011744259856641293, 0.010916410324474176, 0.0109159459049503, 0.010632241144776344, 0.011770392147203287, 0.011374379508197308, 0.012657561339437962, 0.013025601394474506, 0.013477825870116552, 0.015130531042814255, 0.015148110687732697, 0.017218435183167458, 0.01842009462416172, 0.019726600497961044, 0.0207715705037117, 0.022843549648920696, 0.02329447182516257, 0.025592712685465813, 0.028037441273530323, 0.029976985106865566, 0.03133914309243361, 0.03346194326877594, 0.03667105113466581, 0.03878547872106234, 0.04018950338164965, 0.04354700818657875, 0.04535567263762156, 0.047806307673454285, 0.05158948401610056, 0.053359837581714, 0.05789270500342051, 0.05954137692848841, 0.06476437548796336, 0.0675144890944163, 0.06863319377104442, 0.07318517565727234, 0.0735003153483073, 0.07602794965108235, 0.07757585992415746, 0.08224237461884816, 0.08683486531178157, 0.08903479079405467, 0.09215221305688222, 0.09707465767860413, 0.10460849106311798, 0.10424325615167618, 0.12386639416217804, 0.11826375126838684, 0.11759635806083679, 0.12337744484345119, 0.14030898114045462, 0.13299908737341562, 0.13736856480439505, 0.14227711657683054, 0.15087675551573435, 0.15070168177286783, 0.16109625001748404, 0.16625415285428366, 0.16379048923651376, 0.17307602862517038, 0.17556227246920267, 0.18586362401644388, 0.18662029504776, 0.19477449854214987, 0.20097277561823526, 0.2095552682876587, 0.20874479909737906, 0.2206359306971232, 0.2254451165596644, 0.23360797762870789, 0.23987987637519836, 0.24476363261540732, 0.2458098183075587, 0.25296901166439056, 0.26396342118581134, 0.275317261616389, 0.2790987491607666, 0.28892351190249127, 0.32169901331265766, 0.3057444393634796, 0.3076893190542857, 0.3221030632654826, 0.32498647769292194, 0.3344180981318156, 0.334782342116038, 0.3647800385951996, 0.3661533792813619, 0.36108605066935223, 0.37033472458521527, 0.3771851559480031, 0.396592378616333, 0.40354398886362713, 0.4096365173657735, 0.41257039705912274, 0.45246734221776325, 0.4215148389339447, 0.44237325588862103, 0.45414677262306213, 0.4855530460675557], loss_1_list: [0.6931474804878235, 0.5446271896362305, 0.5331935087839762, 0.5181525349617004, 0.5277948975563049, 0.5134608149528503, 0.5239590803782145, 0.5186187823613485, 0.5131832857926687, 0.5239212910334269, 0.5102942089239756, 0.5236284136772156, 0.5235580603281657, 0.5235108931859335, 0.5189940532048544, 0.5257082978884379, 0.5122336049874624, 0.5189225474993387, 0.5255869626998901, 0.5255192915598551, 0.5187166531880697, 0.5186663667360941, 0.5276230971018473, 0.5253493587176005, 0.5163456002871195, 0.5231019457181295, 0.5164122978846232, 0.5143232345581055, 0.5213735898335775, 0.513308048248291, 0.5240529378255209, 0.5153283874193827, 0.5293986598650614, 0.5255963802337646, 0.5119524498780569, 0.5191502173741659, 0.5003428558508555, 0.49132070938746136, 0.48145171999931335, 0.4851478735605876, 0.48828856150309247, 0.47993165254592896, 0.47601477305094403, 0.4794987738132477, 0.49310067296028137, 0.47461241483688354, 0.5322409470876058, 0.4935264786084493, 0.47453763087590534, 0.4786097009976705, 0.5190738836924235, 0.4786207675933838, 0.47690510749816895, 0.4764116704463959, 0.486706684033076, 0.4711098372936249, 0.4851621190706889, 0.4842921396096547, 0.46347038944562274, 0.47302666306495667, 0.46528170506159466, 0.47641350825627643, 0.46452651421229046, 0.4697359601656596, 0.47018106778462726, 0.47551266352335614, 0.4607899884382884, 0.47243016958236694, 0.46927712361017865, 0.4725830852985382, 0.4719947079817454, 0.4687161445617676, 0.45850521326065063, 0.45934905608495075, 0.46654194593429565, 0.47381136814753216, 0.46828846136728924, 0.4724523325761159, 0.5119011203447977, 0.475554754336675, 0.4671955406665802, 0.47711731990178424, 0.4701856275399526, 0.47245510419209796, 0.4622102677822113, 0.4915949006875356, 0.48244701822598773, 0.4653558333714803, 0.46669431527455646, 0.46493255098660785, 0.47813600301742554, 0.47611089547475177, 0.47306928038597107, 0.46650245785713196, 0.5008097986380259, 0.4571490486462911, 0.4699517786502838, 0.47273000081380206, 0.4953176975250244], loss_2_list: [0.011744259856641293, 0.010861950305600962, 0.010702705942094326, 0.010165770538151264, 0.010926612031956514, 0.01009040263791879, 0.010772578418254852, 0.010485192760825157, 0.010193328373134136, 0.010890608342985312, 0.01004403829574585, 0.01088831014931202, 0.010887748251358667, 0.01088736237337192, 0.010604822697738806, 0.011028119052449862, 0.010180965686837832, 0.010604032936195532, 0.011027202320595583, 0.011026691334942976, 0.010601880960166454, 0.010601351658503214, 0.01116704847663641, 0.011025308320919672, 0.010458781073490778, 0.010883338438967863, 0.010458767103652159, 0.010318338560561338, 0.010743219094971815, 0.010188360077639421, 0.010758205937842527, 0.009992585517466068, 0.010556157988806566, 0.010254253633320332, 0.009353027989466986, 0.009483311014870802, 0.008457644221683344, 0.008601976713786522, 0.0077904413143793745, 0.008230382887025675, 0.008511989377439022, 0.008111441197494665, 0.007900187435249487, 0.008153356611728668, 0.008979649282991886, 0.007792951383938392, 0.011423899171253046, 0.009075742214918137, 0.00790012115612626, 0.008118984444687763, 0.010612729315956434, 0.008143246794740358, 0.008003092215706905, 0.008040267663697401, 0.008642890180150667, 0.00766233882556359, 0.00861753678570191, 0.008545765032370886, 0.007176661863923073, 0.0078658830995361, 0.007365216501057148, 0.008045193428794542, 0.007289836959292491, 0.007647958428909381, 0.007690191424141328, 0.008036251179873943, 0.007108650791148345, 0.007852730496476093, 0.007658911558489005, 0.007861838520814976, 0.00781240841994683, 0.007590400365491708, 0.006993954535573721, 0.007038947660475969, 0.007473262337346871, 0.007949138836314281, 0.007605607000490029, 0.007894999502847591, 0.010375439810256163, 0.00805172851930062, 0.007530659902840853, 0.008199201431125402, 0.007690731901675463, 0.007860061091681322, 0.007229883534212907, 0.009097816422581673, 0.00852027970055739, 0.007493781701972087, 0.007569181888053815, 0.0074792470162113505, 0.00828938124080499, 0.008197575807571411, 0.008069701182345549, 0.00765872389699022, 0.009820892785986265, 0.00708353395263354, 0.007905536486456791, 0.008101506624370813, 0.00951405211041371]
Test
inquiry 0
model storage/model.ep801 loaded.
0it [00:00, ?it/s]/home/teamcommon/pjy/Bipedal_walker/criticality/stage2/my_test.py:228: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels_cls = torch.tensor(labels[:, 0], dtype=torch.int64)
1it [00:02,  2.87s/it]2it [00:05,  2.46s/it]3it [00:07,  2.52s/it]4it [00:10,  2.67s/it]5it [00:13,  2.75s/it]6it [00:16,  2.79s/it]7it [00:19,  2.82s/it]8it [00:21,  2.82s/it]9it [00:24,  2.78s/it]10it [00:26,  2.51s/it]11it [00:29,  2.61s/it]12it [00:32,  2.68s/it]13it [00:35,  2.76s/it]14it [00:38,  2.77s/it]15it [00:40,  2.81s/it]16it [00:43,  2.77s/it]17it [00:45,  2.58s/it]18it [00:48,  2.67s/it]19it [00:51,  2.74s/it]20it [00:54,  2.79s/it]21it [00:57,  2.82s/it]22it [00:59,  2.74s/it]23it [01:02,  2.59s/it]24it [01:05,  2.69s/it]25it [01:07,  2.66s/it]26it [01:10,  2.73s/it]27it [01:13,  2.79s/it]28it [01:16,  2.80s/it]29it [01:18,  2.55s/it]30it [01:21,  2.64s/it]31it [01:26,  3.53s/it]32it [01:32,  4.33s/it]33it [01:38,  4.72s/it]34it [01:44,  5.13s/it]35it [01:50,  5.44s/it]36it [01:56,  5.49s/it]37it [02:02,  5.70s/it]38it [02:08,  5.81s/it]39it [02:14,  5.89s/it]40it [02:20,  5.83s/it]41it [02:26,  5.90s/it]42it [02:32,  5.98s/it]43it [02:38,  5.86s/it]44it [02:44,  5.93s/it]45it [02:50,  6.01s/it]46it [02:56,  5.90s/it]47it [03:02,  5.96s/it]48it [03:08,  6.01s/it]49it [03:14,  5.91s/it]50it [03:20,  5.95s/it]51it [03:26,  6.01s/it]52it [03:32,  6.09s/it]53it [03:38,  5.95s/it]54it [03:44,  5.99s/it]55it [03:50,  6.03s/it]56it [03:55,  5.87s/it]57it [04:01,  5.94s/it]58it [04:08,  5.98s/it]59it [04:14,  6.02s/it]60it [04:19,  5.88s/it]61it [04:25,  5.94s/it]62it [04:31,  5.98s/it]63it [04:37,  5.82s/it]63it [04:37,  4.40s/it]
TP is [156, 156, 156, 156, 156, 156, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
FP is [64267, 64267, 64267, 64267, 64267, 64267, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
TN is [0, 0, 0, 0, 0, 0, 64267, 64267, 64267, 64267, 64267, 64267, 64267, 64267, 64267, 64267, 64267, 64267, 64267]
FN is [0, 0, 0, 0, 0, 0, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156]

TPR is [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
FPR is [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
precison is [0.0024214954286512582, 0.0024214954286512582, 0.0024214954286512582, 0.0024214954286512582, 0.0024214954286512582, 0.0024214954286512582, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]

figure generated
inquiry 1
model storage/model.ep826 loaded.
0it [00:00, ?it/s]1it [00:05,  5.55s/it]2it [00:11,  5.88s/it]3it [00:17,  6.00s/it]4it [00:23,  5.85s/it]5it [00:29,  5.94s/it]6it [00:35,  6.03s/it]7it [00:41,  5.91s/it]8it [00:47,  5.98s/it]9it [00:53,  6.03s/it]10it [00:59,  5.92s/it]11it [01:05,  5.99s/it]12it [01:11,  6.03s/it]13it [01:17,  6.03s/it]14it [01:23,  5.93s/it]15it [01:29,  5.99s/it]16it [01:35,  6.01s/it]17it [01:41,  5.94s/it]18it [01:47,  6.00s/it]19it [01:53,  6.06s/it]20it [01:59,  6.04s/it]21it [02:05,  5.92s/it]22it [02:11,  5.99s/it]23it [02:17,  5.99s/it]24it [02:23,  5.98s/it]25it [02:29,  6.04s/it]26it [02:35,  6.07s/it]27it [02:41,  5.95s/it]28it [02:47,  6.01s/it]29it [02:53,  6.06s/it]30it [02:59,  6.09s/it]31it [03:05,  5.95s/it]32it [03:11,  6.01s/it]33it [03:17,  5.90s/it]34it [03:23,  5.96s/it]35it [03:29,  6.04s/it]36it [03:35,  6.08s/it]37it [03:41,  5.92s/it]38it [03:47,  5.99s/it]39it [03:53,  6.04s/it]40it [03:59,  5.92s/it]41it [04:05,  5.98s/it]42it [04:11,  6.01s/it]43it [04:17,  5.90s/it]44it [04:23,  5.95s/it]45it [04:28,  5.87s/it]46it [04:34,  5.88s/it]47it [04:40,  5.97s/it]48it [04:47,  6.00s/it]49it [04:52,  5.98s/it]50it [04:59,  6.05s/it]51it [05:05,  6.02s/it]52it [05:11,  5.97s/it]53it [05:17,  6.02s/it]54it [05:23,  6.06s/it]55it [05:29,  5.96s/it]56it [05:35,  6.05s/it]57it [05:41,  6.04s/it]58it [05:47,  6.05s/it]59it [05:53,  5.94s/it]60it [05:59,  6.01s/it]61it [06:05,  6.06s/it]62it [06:11,  5.94s/it]63it [06:16,  5.86s/it]63it [06:16,  5.98s/it]
TP is [156, 156, 156, 156, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
FP is [64267, 64267, 64267, 64267, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
TN is [0, 0, 0, 0, 64267, 64267, 64267, 64267, 64267, 64267, 64267, 64267, 64267, 64267, 64267, 64267, 64267, 64267, 64267]
FN is [0, 0, 0, 0, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156]

TPR is [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
FPR is [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
precison is [0.0024214954286512582, 0.0024214954286512582, 0.0024214954286512582, 0.0024214954286512582, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]

figure generated
inquiry 2
model storage/model.ep851 loaded.
0it [00:00, ?it/s]1it [00:06,  6.24s/it]2it [00:11,  5.92s/it]3it [00:17,  5.94s/it]4it [00:24,  6.03s/it]5it [00:30,  6.07s/it]6it [00:36,  6.08s/it]7it [00:41,  5.84s/it]8it [00:47,  5.94s/it]9it [00:53,  6.01s/it]10it [01:00,  6.06s/it]11it [01:05,  5.91s/it]12it [01:11,  5.97s/it]13it [01:17,  6.02s/it]14it [01:23,  5.90s/it]15it [01:29,  5.96s/it]16it [01:35,  6.00s/it]17it [01:41,  5.89s/it]18it [01:47,  5.97s/it]19it [01:53,  6.03s/it]20it [01:59,  5.91s/it]21it [02:05,  5.97s/it]22it [02:11,  6.05s/it]23it [02:17,  6.04s/it]24it [02:23,  5.91s/it]25it [02:29,  5.97s/it]26it [02:35,  6.01s/it]27it [02:41,  6.02s/it]28it [02:47,  5.92s/it]29it [02:53,  6.02s/it]30it [02:59,  6.08s/it]31it [03:05,  5.96s/it]32it [03:11,  6.00s/it]33it [03:17,  6.06s/it]34it [03:23,  6.07s/it]35it [03:29,  5.95s/it]36it [03:35,  6.02s/it]37it [03:41,  6.04s/it]38it [03:47,  5.95s/it]39it [03:53,  6.01s/it]40it [03:59,  6.06s/it]41it [04:05,  6.10s/it]42it [04:11,  5.95s/it]43it [04:17,  5.99s/it]44it [04:23,  6.03s/it]45it [04:29,  5.87s/it]46it [04:35,  5.95s/it]47it [04:41,  6.04s/it]48it [04:47,  6.06s/it]49it [04:53,  5.94s/it]50it [04:59,  5.97s/it]51it [05:05,  6.04s/it]52it [05:11,  5.94s/it]53it [05:17,  6.01s/it]54it [05:23,  6.03s/it]55it [05:29,  6.02s/it]56it [05:35,  5.96s/it]57it [05:41,  6.03s/it]58it [05:47,  6.04s/it]59it [05:53,  5.92s/it]60it [05:59,  5.97s/it]61it [06:05,  6.05s/it]62it [06:11,  5.95s/it]63it [06:17,  5.86s/it]63it [06:17,  5.99s/it]
TP is [156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 0, 0, 0, 0]
FP is [64267, 64267, 64267, 64267, 13825, 13132, 12981, 12869, 12537, 12187, 12111, 11986, 11887, 11735, 10877, 0, 0, 0, 0]
TN is [0, 0, 0, 0, 50442, 51135, 51286, 51398, 51730, 52080, 52156, 52281, 52380, 52532, 53390, 64267, 64267, 64267, 64267]
FN is [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 156, 156, 156, 156]

TPR is [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]
FPR is [1.0, 1.0, 1.0, 1.0, 0.21511817884762008, 0.20433503975601786, 0.2019854668803585, 0.20024273733020057, 0.19507678902080383, 0.18963075917656028, 0.18844819269609597, 0.18650318203743757, 0.1849627335957801, 0.18259760063485148, 0.16924704747382016, 0.0, 0.0, 0.0, 0.0]
precison is [0.0024214954286512582, 0.0024214954286512582, 0.0024214954286512582, 0.0024214954286512582, 0.011158000143051284, 0.011739915713425647, 0.01187485727335008, 0.011976967370441459, 0.01229023871425195, 0.01263874260714575, 0.012717045732452923, 0.01284796573875803, 0.01295358299427053, 0.013119165755613489, 0.014139399981872565, 1, 1, 1, 1]

figure generated
inquiry 3
model storage/model.ep876 loaded.
0it [00:00, ?it/s]1it [00:06,  6.16s/it]2it [00:11,  5.88s/it]3it [00:18,  6.03s/it]4it [00:24,  6.08s/it]5it [00:29,  5.97s/it]6it [00:35,  5.98s/it]7it [00:41,  5.99s/it]8it [00:48,  6.04s/it]9it [00:54,  6.03s/it]10it [00:59,  5.90s/it]11it [01:05,  5.98s/it]12it [01:12,  6.03s/it]13it [01:17,  5.95s/it]14it [01:23,  6.02s/it]15it [01:30,  6.06s/it]16it [01:36,  6.08s/it]17it [01:41,  5.92s/it]18it [01:47,  5.99s/it]19it [01:54,  6.04s/it]20it [02:00,  6.08s/it]21it [02:05,  5.88s/it]22it [02:11,  5.95s/it]23it [02:17,  6.00s/it]24it [02:23,  5.83s/it]25it [02:29,  5.93s/it]26it [02:35,  6.01s/it]27it [02:41,  6.04s/it]28it [02:47,  5.91s/it]29it [02:53,  5.99s/it]30it [02:59,  6.03s/it]31it [03:05,  5.91s/it]32it [03:11,  5.94s/it]33it [03:17,  6.01s/it]34it [03:23,  6.06s/it]35it [03:29,  5.92s/it]36it [03:35,  6.01s/it]37it [03:41,  6.06s/it]38it [03:47,  6.09s/it]39it [03:53,  5.95s/it]40it [03:59,  6.01s/it]41it [04:05,  5.99s/it]42it [04:11,  6.04s/it]43it [04:17,  5.92s/it]44it [04:23,  6.01s/it]45it [04:29,  6.04s/it]46it [04:35,  5.91s/it]47it [04:41,  5.99s/it]48it [04:47,  6.03s/it]49it [04:53,  6.05s/it]50it [04:59,  5.91s/it]51it [05:05,  5.96s/it]52it [05:11,  6.02s/it]53it [05:17,  5.91s/it]54it [05:23,  5.92s/it]55it [05:29,  5.99s/it]56it [05:35,  5.91s/it]57it [05:41,  5.94s/it]58it [05:47,  5.99s/it]59it [05:53,  6.01s/it]60it [05:58,  5.91s/it]61it [06:05,  5.97s/it]62it [06:11,  6.02s/it]63it [06:16,  5.92s/it]63it [06:16,  5.98s/it]
TP is [156, 156, 156, 156, 150, 150, 150, 150, 148, 148, 148, 148, 147, 147, 146, 0, 0, 0, 0]
FP is [64267, 64267, 64267, 64267, 5349, 5117, 5030, 4980, 4699, 4617, 4524, 4507, 4455, 4324, 4142, 0, 0, 0, 0]
TN is [0, 0, 0, 0, 58918, 59150, 59237, 59287, 59568, 59650, 59743, 59760, 59812, 59943, 60125, 64267, 64267, 64267, 64267]
FN is [0, 0, 0, 0, 6, 6, 6, 6, 8, 8, 8, 8, 9, 9, 10, 156, 156, 156, 156]

TPR is [1.0, 1.0, 1.0, 1.0, 0.9615384615384616, 0.9615384615384616, 0.9615384615384616, 0.9615384615384616, 0.9487179487179487, 0.9487179487179487, 0.9487179487179487, 0.9487179487179487, 0.9423076923076923, 0.9423076923076923, 0.9358974358974359, 0.0, 0.0, 0.0, 0.0]
FPR is [1.0, 1.0, 1.0, 1.0, 0.08323089610531066, 0.07962095632284065, 0.0782672289044144, 0.07748922464095104, 0.07311684068028693, 0.07184091368820701, 0.07039382575816515, 0.07012930430858762, 0.06932017987458572, 0.0672818087043117, 0.06444987318530505, 0.0, 0.0, 0.0, 0.0]
precison is [0.0024214954286512582, 0.0024214954286512582, 0.0024214954286512582, 0.0024214954286512582, 0.027277686852154936, 0.028479210176571103, 0.02895752895752896, 0.029239766081871343, 0.030534351145038167, 0.0310598111227702, 0.031678082191780824, 0.0317937701396348, 0.031942633637548894, 0.03287855065980765, 0.03404850746268657, 1, 1, 1, 1]

figure generated
final test
model storage/model.ep899 loaded.
0it [00:00, ?it/s]1it [00:06,  6.16s/it]2it [00:12,  6.10s/it]3it [00:18,  6.08s/it]4it [00:23,  5.85s/it]5it [00:29,  5.94s/it]6it [00:35,  6.00s/it]7it [00:42,  6.03s/it]8it [00:47,  5.85s/it]9it [00:53,  5.92s/it]10it [00:59,  5.97s/it]11it [01:05,  5.97s/it]12it [01:11,  5.88s/it]13it [01:17,  5.95s/it]14it [01:23,  5.98s/it]15it [01:29,  5.87s/it]16it [01:35,  5.94s/it]17it [01:41,  5.99s/it]18it [01:46,  5.89s/it]19it [01:53,  5.97s/it]20it [01:59,  6.03s/it]21it [02:05,  6.08s/it]22it [02:11,  5.91s/it]23it [02:17,  5.98s/it]24it [02:23,  6.04s/it]25it [02:28,  5.85s/it]26it [02:34,  5.92s/it]27it [02:40,  5.97s/it]28it [02:47,  6.00s/it]29it [02:52,  5.86s/it]30it [02:58,  5.94s/it]31it [03:04,  5.98s/it]32it [03:10,  5.88s/it]33it [03:16,  5.96s/it]34it [03:22,  6.00s/it]35it [03:28,  5.87s/it]36it [03:34,  5.96s/it]37it [03:40,  6.01s/it]38it [03:46,  6.00s/it]39it [03:52,  5.98s/it]40it [03:58,  6.00s/it]41it [04:04,  5.92s/it]42it [04:10,  5.96s/it]43it [04:16,  5.98s/it]44it [04:21,  5.90s/it]45it [04:28,  5.96s/it]46it [04:34,  6.03s/it]47it [04:40,  5.99s/it]48it [04:45,  5.86s/it]49it [04:51,  5.94s/it]50it [04:57,  5.99s/it]51it [05:04,  6.01s/it]52it [05:09,  5.85s/it]53it [05:15,  5.86s/it]54it [05:21,  5.90s/it]55it [05:27,  5.97s/it]56it [05:32,  5.83s/it]57it [05:39,  5.91s/it]58it [05:45,  5.96s/it]59it [05:51,  6.01s/it]60it [05:56,  5.90s/it]61it [06:03,  5.96s/it]62it [06:09,  6.03s/it]63it [06:14,  5.89s/it]63it [06:14,  5.95s/it]
TP is [156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 156, 0, 0, 0, 0]
FP is [64267, 64267, 64267, 64267, 10001, 9777, 9693, 9668, 9563, 9502, 9484, 9475, 9475, 9394, 9197, 0, 0, 0, 0]
TN is [0, 0, 0, 0, 54266, 54490, 54574, 54599, 54704, 54765, 54783, 54792, 54792, 54873, 55070, 64267, 64267, 64267, 64267]
FN is [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 156, 156, 156, 156]

TPR is [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]
FPR is [1.0, 1.0, 1.0, 1.0, 0.15561641277794203, 0.15213095367762616, 0.1508239065150077, 0.15043490438327603, 0.14880109543000294, 0.14785193022857765, 0.14757184869373083, 0.14743180792630745, 0.14743180792630745, 0.14617144101949678, 0.14310610422145115, 0.0, 0.0, 0.0, 0.0]
precison is [0.0024214954286512582, 0.0024214954286512582, 0.0024214954286512582, 0.0024214954286512582, 0.015358865806832727, 0.01570522500755059, 0.015839171489491318, 0.015879478827361564, 0.01605103405700175, 0.016152412507765584, 0.016182572614107885, 0.0161976949434119, 0.0161976949434119, 0.016335078534031412, 0.016679140382764888, 1, 1, 1, 1]

figure generated
